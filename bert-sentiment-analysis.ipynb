{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-01T16:06:58.297417Z",
     "iopub.status.busy": "2025-04-01T16:06:58.296687Z",
     "iopub.status.idle": "2025-04-01T16:07:05.559013Z",
     "shell.execute_reply": "2025-04-01T16:07:05.558445Z",
     "shell.execute_reply.started": "2025-03-31T09:16:33.350809Z"
    },
    "papermill": {
     "duration": 7.275164,
     "end_time": "2025-04-01T16:07:05.559115",
     "exception": false,
     "start_time": "2025-04-01T16:06:58.283951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:07:05.578939Z",
     "iopub.status.busy": "2025-04-01T16:07:05.578411Z",
     "iopub.status.idle": "2025-04-01T16:07:05.596991Z",
     "shell.execute_reply": "2025-04-01T16:07:05.597377Z",
     "shell.execute_reply.started": "2025-03-31T09:16:40.896882Z"
    },
    "papermill": {
     "duration": 0.030238,
     "end_time": "2025-04-01T16:07:05.597502",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.567264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/bert-base-uncased/config.json\n",
      "/kaggle/input/bert-base-uncased/pytorch_model.bin\n",
      "/kaggle/input/bert-base-uncased/vocab.txt\n",
      "/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00709,
     "end_time": "2025-04-01T16:07:05.612068",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.604978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2025-04-01T16:07:05.630909Z",
     "iopub.status.busy": "2025-04-01T16:07:05.630428Z",
     "iopub.status.idle": "2025-04-01T16:07:05.681637Z",
     "shell.execute_reply": "2025-04-01T16:07:05.681049Z",
     "shell.execute_reply.started": "2025-03-31T09:16:40.916743Z"
    },
    "papermill": {
     "duration": 0.06239,
     "end_time": "2025-04-01T16:07:05.681749",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.619359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config():\n",
    "    MAX_LEN = 512\n",
    "    TRAIN_BATCH_SIZE = 8\n",
    "    VALID_BATCH_SIZE = 4\n",
    "    EPOCHS = 3\n",
    "    BERT_PATH = '../input/bert-base-uncased'\n",
    "    MODEL_PATH = 'model.bin'\n",
    "    TRAINING_FILE = \"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\"\n",
    "    TOKENIZER = transformers.BertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00745,
     "end_time": "2025-04-01T16:07:05.696999",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.689549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:07:05.718750Z",
     "iopub.status.busy": "2025-04-01T16:07:05.718123Z",
     "iopub.status.idle": "2025-04-01T16:07:05.720811Z",
     "shell.execute_reply": "2025-04-01T16:07:05.720291Z",
     "shell.execute_reply.started": "2025-03-31T09:16:40.998389Z"
    },
    "papermill": {
     "duration": 0.01634,
     "end_time": "2025-04-01T16:07:05.720904",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.704564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTBaseUncased(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTBaseUncased, self).__init__()\n",
    "        self.bert       = transformers.BertModel.from_pretrained(config.BERT_PATH)\n",
    "        self.bert_drop  = nn.Dropout(0.3)\n",
    "        self.out        = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        out1, out2 = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        bo         = self.bert_drop(out2)\n",
    "        output     = self.out(bo)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007127,
     "end_time": "2025-04-01T16:07:05.735534",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.728407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset or DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:07:05.758618Z",
     "iopub.status.busy": "2025-04-01T16:07:05.757820Z",
     "iopub.status.idle": "2025-04-01T16:07:05.759862Z",
     "shell.execute_reply": "2025-04-01T16:07:05.760312Z",
     "shell.execute_reply.started": "2025-03-31T09:16:41.007587Z"
    },
    "papermill": {
     "duration": 0.017498,
     "end_time": "2025-04-01T16:07:05.760437",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.742939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTDataset:\n",
    "    def __init__(self,  review, target):\n",
    "        self.review    = review\n",
    "        self.target    = target\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "        self.max_len   = config.MAX_LEN\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.review)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.review[item])\n",
    "        review = ' '.join(review.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(review, None, add_special_tokens=True, max_length=self.max_len, pad_to_max_length=True)\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.target[item], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007132,
     "end_time": "2025-04-01T16:07:05.775002",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.767870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:07:05.793856Z",
     "iopub.status.busy": "2025-04-01T16:07:05.793280Z",
     "iopub.status.idle": "2025-04-01T16:07:05.795896Z",
     "shell.execute_reply": "2025-04-01T16:07:05.795408Z",
     "shell.execute_reply.started": "2025-03-31T09:16:41.019548Z"
    },
    "papermill": {
     "duration": 0.013707,
     "end_time": "2025-04-01T16:07:05.795983",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.782276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:07:05.818369Z",
     "iopub.status.busy": "2025-04-01T16:07:05.817698Z",
     "iopub.status.idle": "2025-04-01T16:07:05.819883Z",
     "shell.execute_reply": "2025-04-01T16:07:05.820277Z",
     "shell.execute_reply.started": "2025-03-31T09:16:41.039888Z"
    },
    "papermill": {
     "duration": 0.015928,
     "end_time": "2025-04-01T16:07:05.820392",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.804464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "\n",
    "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d['ids']\n",
    "        token_type_ids = d['token_type_ids']\n",
    "        mask = d['mask']\n",
    "        targets = d['targets']\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:07:05.842809Z",
     "iopub.status.busy": "2025-04-01T16:07:05.842330Z",
     "iopub.status.idle": "2025-04-01T16:07:05.844959Z",
     "shell.execute_reply": "2025-04-01T16:07:05.844530Z",
     "shell.execute_reply.started": "2025-03-31T09:16:41.051267Z"
    },
    "papermill": {
     "duration": 0.017203,
     "end_time": "2025-04-01T16:07:05.845042",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.827839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids            = d['ids']\n",
    "            token_type_ids = d['token_type_ids']\n",
    "            mask           = d['mask']\n",
    "            targets        = d['targets']\n",
    "\n",
    "            ids            = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask           = mask.to(device, dtype=torch.long)\n",
    "            targets        = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
    "\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007262,
     "end_time": "2025-04-01T16:07:05.859729",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.852467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:07:05.888530Z",
     "iopub.status.busy": "2025-04-01T16:07:05.887993Z",
     "iopub.status.idle": "2025-04-01T18:05:22.292342Z",
     "shell.execute_reply": "2025-04-01T18:05:22.291729Z",
     "shell.execute_reply.started": "2025-03-31T09:16:41.066295Z"
    },
    "papermill": {
     "duration": 7096.425002,
     "end_time": "2025-04-01T18:05:22.292467",
     "exception": false,
     "start_time": "2025-04-01T16:07:05.867465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [36:15<00:00,  2.30it/s]\n",
      "100%|██████████| 2500/2500 [03:06<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score =  0.9419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [36:14<00:00,  2.30it/s]\n",
      "100%|██████████| 2500/2500 [03:06<00:00, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score =  0.9416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5000/5000 [36:14<00:00,  2.30it/s]\n",
      "100%|██████████| 2500/2500 [03:05<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score =  0.9446\n"
     ]
    }
   ],
   "source": [
    "dfx = pd.read_csv(config.TRAINING_FILE).fillna('none')\n",
    "dfx.sentiment = dfx.sentiment.apply(lambda x: 1 if x == 'positive' else 0)\n",
    "\n",
    "df_train, df_valid = model_selection.train_test_split(dfx, test_size=0.2, random_state=42, stratify=dfx.sentiment.values)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_valid = df_valid.reset_index(drop=True)\n",
    "\n",
    "train_dataset = BERTDataset(\n",
    "    review=df_train.review.values,\n",
    "    target=df_train.sentiment.values\n",
    ")\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.TRAIN_BATCH_SIZE,\n",
    "    num_workers=4 # (4) in windows gotta be 0\n",
    ")\n",
    "\n",
    "valid_dataset = BERTDataset(\n",
    "    review=df_valid.review.values,\n",
    "    target=df_valid.sentiment.values\n",
    ")\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=config.VALID_BATCH_SIZE,\n",
    "    num_workers=1 # (1)\n",
    ")\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = BERTBaseUncased()\n",
    "model.to(device)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
    "optimizer = AdamW(optimizer_parameters, lr=3e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_train_steps\n",
    "    #warmup_steps = 0, # transformers 2.1.0\n",
    "    #t_total = num_train_steps  # transformers 2.1.0\n",
    ")\n",
    "\n",
    "#model = nn.DataParallel(model)\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(config.EPOCHS):\n",
    "    train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
    "    outputs, targets = eval_fn(valid_data_loader, model, device)\n",
    "    outputs = np.array(outputs) >= 0.5\n",
    "\n",
    "    acc = metrics.accuracy_score(targets, outputs) # we can use accuracy, as the dataset is balanced\n",
    "    print('Accuracy score = ', acc)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        torch.save(model.state_dict(), config.MODEL_PATH)\n",
    "        best_acc = acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 3.860868,
     "end_time": "2025-04-01T18:05:29.983618",
     "exception": false,
     "start_time": "2025-04-01T18:05:26.122750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 134715,
     "sourceId": 320111,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 431504,
     "sourceId": 819665,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29981,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 7119.317851,
   "end_time": "2025-04-01T18:05:34.145118",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-01T16:06:54.827267",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
